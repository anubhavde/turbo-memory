{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Google AI4Code – Understand Code in Python Notebooks**\n",
    "##### Predict the relationship between code and comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "\n",
    "data_dir = Path(\"/home/linux/Workspace/AI4Code/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train NBs: 100%|██████████| 10000/10000 [00:38<00:00, 261.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">001308991e0c5e</th>\n",
       "      <th>6c01d0d2</th>\n",
       "      <td>code</td>\n",
       "      <td># This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8fd3a8c</th>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n%matplotlib inline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94d3d43a</th>\n",
       "      <td>code</td>\n",
       "      <td>df.dropna()\\ndf.head()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9ecece20</th>\n",
       "      <td>code</td>\n",
       "      <td>df.shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808d31ab</th>\n",
       "      <td>code</td>\n",
       "      <td>df.columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">fffc3b44869198</th>\n",
       "      <th>40e930ff</th>\n",
       "      <td>code</td>\n",
       "      <td>test['bookID']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1873cbb</th>\n",
       "      <td>code</td>\n",
       "      <td>df = pd.DataFrame(np.nan, index=[0,1,2,3], columns=['A'])\\ndf['bookID'] = test['bookID']\\ndf['average_rating'] = pd....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76e0f2a7</th>\n",
       "      <td>code</td>\n",
       "      <td>df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233d93b9</th>\n",
       "      <td>code</td>\n",
       "      <td>df.to_csv('file_name.csv', index=False)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ac536a5b</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Lets make test dataset looks like train dataset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449506 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        cell_type                                                                                                                   source\n",
       "id             cell_id                                                                                                                                    \n",
       "001308991e0c5e 6c01d0d2      code  # This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/pyt...\n",
       "               b8fd3a8c      code      import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n%matplotlib inline\n",
       "               94d3d43a      code                                                                                                   df.dropna()\\ndf.head()\n",
       "               9ecece20      code                                                                                                                 df.shape\n",
       "               808d31ab      code                                                                                                               df.columns\n",
       "...                           ...                                                                                                                      ...\n",
       "fffc3b44869198 40e930ff      code                                                                                                           test['bookID']\n",
       "               b1873cbb      code  df = pd.DataFrame(np.nan, index=[0,1,2,3], columns=['A'])\\ndf['bookID'] = test['bookID']\\ndf['average_rating'] = pd....\n",
       "               76e0f2a7      code                                                                                                                       df\n",
       "               233d93b9      code                                                                                  df.to_csv('file_name.csv', index=False)\n",
       "               ac536a5b  markdown                                                                        # Lets make test dataset looks like train dataset\n",
       "\n",
       "[449506 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_TRAIN = 10000\n",
    "\n",
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(\n",
    "            path,\n",
    "            dtype={'cell_type': 'category', 'source': 'str'})\n",
    "        .assign(id=path.stem)\n",
    "        .rename_axis('cell_id')\n",
    "    )\n",
    "\n",
    "paths_train = list((data_dir / 'train').glob('*.json'))[:NUM_TRAIN]\n",
    "notebooks_train = [\n",
    "    read_notebook(path) for path in tqdm(paths_train, desc='Train NBs')\n",
    "]\n",
    "df = (\n",
    "    pd.concat(notebooks_train)\n",
    "    .set_index('id', append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level='id', sort_remaining=False)\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook:  002b5d330ee1ec\n",
      "The disordered notebook: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cb79667a</th>\n",
       "      <td>code</td>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06a365fd</th>\n",
       "      <td>code</td>\n",
       "      <td>train_df = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0b58ebf1</th>\n",
       "      <td>code</td>\n",
       "      <td>train_df.head()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72603136</th>\n",
       "      <td>code</td>\n",
       "      <td>train_df.shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21184871</th>\n",
       "      <td>code</td>\n",
       "      <td>train_df = train_df.drop(['Alley','PoolQC','Fence','MiscFeature'], axis=1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a14531e8</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Categorical Columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6adf0356</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Numeric columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146526c</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Concatenate Test and Training data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2d7a8c99</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Missing data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8770a100</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Training Data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_type                                                                                           source\n",
       "cell_id                                                                                                            \n",
       "cb79667a      code  import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\n",
       "06a365fd      code         train_df = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\n",
       "0b58ebf1      code                                                                                  train_df.head()\n",
       "72603136      code                                                                                   train_df.shape\n",
       "21184871      code                       train_df = train_df.drop(['Alley','PoolQC','Fence','MiscFeature'], axis=1)\n",
       "...            ...                                                                                              ...\n",
       "a14531e8  markdown                                                                            # Categorical Columns\n",
       "6adf0356  markdown                                                                                # Numeric columns\n",
       "6146526c  markdown                                                             # Concatenate Test and Training data\n",
       "2d7a8c99  markdown                                                                                   # Missing data\n",
       "8770a100  markdown                                                                                  # Training Data\n",
       "\n",
       "[119 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nb_id = df.index.unique('id')[6]\n",
    "print('Notebook: ', nb_id)\n",
    "\n",
    "print(\"The disordered notebook: \")\n",
    "nb = df.loc[nb_id, :]\n",
    "display(nb)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ordering the Cells**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3694/363037603.py:1: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  df_orders = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "00001756c60be8    [1862f0a6, 448eb224, 2a9e43d6, 7e2f170a, 038b763d, 77e56113, 2eefe0ef, 1ae087ab, 0beab1cd, 8ffe0b25, 9a78ab76, 0d136...\n",
       "00015c83e2717b    [2e94bd7a, 3e99dee9, b5e286ea, da4f7550, c417225b, 51e3cd89, 2600b4eb, 75b65993, cf195f8b, 25699d02, 72b3201a, f2c75...\n",
       "0001bdd4021779    [3fdc37be, 073782ca, 8ea7263c, 80543cd8, 38310c80, 073e27e5, 015d52a4, ad7679ef, 7fde4f04, 07c52510, 0a1a7a39, 0bcd3...\n",
       "0001daf4c2c76d    [97266564, a898e555, 86605076, 76cc2642, ef279279, df6c939f, 2476da96, 00f87d0a, ae93e8e6, 58aadb1d, d20b0094, 986fd...\n",
       "0002115f48f982                                 [9ec225f0, 18281c6c, e3b6b115, 4a044c54, 365fe576, a3188e54, b3f6e12d, ee7655ca, 84125b7a]\n",
       "                                                                           ...                                                           \n",
       "fffc30d5a0bc46    [09727c0c, ff1ea6a0, ddfef603, a01ce9b3, 3ba953ee, bf92a015, f4a0492a, 095812e6, 53125cfe, aa32a700, 63340e73, 06d8c...\n",
       "fffc3b44869198    [978a5137, faa48f03, 28dfb12a, eea2e812, 64fef97c, 4e0d1510, 58e68f2c, 8784e700, 4bd5a4cf, dc14bfec, 2aff7603, 8047d...\n",
       "fffc63ff750064    [5015c300, 411b85d9, 8238198c, f4781d1d, b5532930, e1f223e5, e7e67119, 4aaf741d, 7229cce6, a7fa3628, e4c2fa86, 1f8f9...\n",
       "fffcd063cda949    [7e6266ad, d8281fc5, d4ffcaef, 3e0e4a47, 21387fc8, cc229f9a, baed9c8b, d1bb21aa, 82979992, 65f95dad, eba4fa9e, c97e2...\n",
       "fffe1d764579d5    [1a63248d, 9c3b96a5, 1398a873, 4e2d4c2d, f71c538e, 8b44a5e8, 385dff7a, b8254ef8, 4d0e433e, debc496c, e15ae953, e4d79...\n",
       "Name: cell_order, Length: 139256, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders = pd.read_csv(\n",
    "    data_dir / 'train_orders.csv',\n",
    "    index_col='id',\n",
    "    squeeze=True,\n",
    ").str.split()\n",
    "\n",
    "df_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ordered notebook:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cb79667a</th>\n",
       "      <td>code</td>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8770a100</th>\n",
       "      <td>markdown</td>\n",
       "      <td># Training Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06a365fd</th>\n",
       "      <td>code</td>\n",
       "      <td>train_df = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0b58ebf1</th>\n",
       "      <td>code</td>\n",
       "      <td>train_df.head()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72603136</th>\n",
       "      <td>code</td>\n",
       "      <td>train_df.shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c7db5522</th>\n",
       "      <td>code</td>\n",
       "      <td>len(y_test)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b89986d3</th>\n",
       "      <td>code</td>\n",
       "      <td>sample_submission_df = pd.read_csv('../input/house-prices-advanced-regression-techniques/sample_submission.csv')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bc46c719</th>\n",
       "      <td>code</td>\n",
       "      <td>sample_submission_df['SalePrice'] = y_test\\nsample_submission_df.to_csv('submission.csv', index=False)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95141f76</th>\n",
       "      <td>code</td>\n",
       "      <td>submission_df = pd.read_csv('submission.csv')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f60d4736</th>\n",
       "      <td>code</td>\n",
       "      <td>submission_df</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_type                                                                                                            source\n",
       "cell_id                                                                                                                             \n",
       "cb79667a      code                   import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\n",
       "8770a100  markdown                                                                                                   # Training Data\n",
       "06a365fd      code                          train_df = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\n",
       "0b58ebf1      code                                                                                                   train_df.head()\n",
       "72603136      code                                                                                                    train_df.shape\n",
       "...            ...                                                                                                               ...\n",
       "c7db5522      code                                                                                                       len(y_test)\n",
       "b89986d3      code  sample_submission_df = pd.read_csv('../input/house-prices-advanced-regression-techniques/sample_submission.csv')\n",
       "bc46c719      code            sample_submission_df['SalePrice'] = y_test\\nsample_submission_df.to_csv('submission.csv', index=False)\n",
       "95141f76      code                                                                     submission_df = pd.read_csv('submission.csv')\n",
       "f60d4736      code                                                                                                     submission_df\n",
       "\n",
       "[119 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_order = df_orders.loc[nb_id]\n",
    "\n",
    "print(\"The ordered notebook:\")\n",
    "nb.loc[cell_order, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cb79667a</th>\n",
       "      <td>0</td>\n",
       "      <td>code</td>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06a365fd</th>\n",
       "      <td>2</td>\n",
       "      <td>code</td>\n",
       "      <td>train_df = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0b58ebf1</th>\n",
       "      <td>3</td>\n",
       "      <td>code</td>\n",
       "      <td>train_df.head()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72603136</th>\n",
       "      <td>4</td>\n",
       "      <td>code</td>\n",
       "      <td>train_df.shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21184871</th>\n",
       "      <td>6</td>\n",
       "      <td>code</td>\n",
       "      <td>train_df = train_df.drop(['Alley','PoolQC','Fence','MiscFeature'], axis=1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a14531e8</th>\n",
       "      <td>91</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Categorical Columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6adf0356</th>\n",
       "      <td>87</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Numeric columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146526c</th>\n",
       "      <td>82</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Concatenate Test and Training data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2d7a8c99</th>\n",
       "      <td>5</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Missing data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8770a100</th>\n",
       "      <td>1</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Training Data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          rank cell_type                                                                                           source\n",
       "cell_id                                                                                                                  \n",
       "cb79667a     0      code  import pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\n",
       "06a365fd     2      code         train_df = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\n",
       "0b58ebf1     3      code                                                                                  train_df.head()\n",
       "72603136     4      code                                                                                   train_df.shape\n",
       "21184871     6      code                       train_df = train_df.drop(['Alley','PoolQC','Fence','MiscFeature'], axis=1)\n",
       "...        ...       ...                                                                                              ...\n",
       "a14531e8    91  markdown                                                                            # Categorical Columns\n",
       "6adf0356    87  markdown                                                                                # Numeric columns\n",
       "6146526c    82  markdown                                                             # Concatenate Test and Training data\n",
       "2d7a8c99     5  markdown                                                                                   # Missing data\n",
       "8770a100     1  markdown                                                                                  # Training Data\n",
       "\n",
       "[119 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ranks(base, derived):\n",
    "    return [base.index(d) for d in derived]\n",
    "\n",
    "\n",
    "cell_ranks = get_ranks(cell_order, list(nb.index))\n",
    "nb.insert(0, 'rank', cell_ranks)\n",
    "\n",
    "nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.testing import assert_frame_equal\n",
    "\n",
    "assert_frame_equal(nb.loc[cell_order, :], nb.sort_values('rank'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">001308991e0c5e</th>\n",
       "      <th>6c01d0d2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b8fd3a8c</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94d3d43a</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9ecece20</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808d31ab</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">fffc3b44869198</th>\n",
       "      <th>40e930ff</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1873cbb</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76e0f2a7</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233d93b9</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ac536a5b</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449506 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        rank\n",
       "id             cell_id      \n",
       "001308991e0c5e 6c01d0d2    1\n",
       "               b8fd3a8c    3\n",
       "               94d3d43a    5\n",
       "               9ecece20    6\n",
       "               808d31ab    7\n",
       "...                      ...\n",
       "fffc3b44869198 40e930ff   20\n",
       "               b1873cbb   21\n",
       "               76e0f2a7   22\n",
       "               233d93b9   23\n",
       "               ac536a5b   12\n",
       "\n",
       "[449506 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders_ = df_orders.to_frame().join(\n",
    "    df.reset_index('cell_id').groupby('id')['cell_id'].apply(list),\n",
    "    how='right',\n",
    ")\n",
    "\n",
    "ranks = {}\n",
    "for id_, cell_order, cell_id in df_orders_.itertuples():\n",
    "    ranks[id_] = {'cell_id': cell_id, 'rank': get_ranks(cell_order, cell_id)}\n",
    "\n",
    "df_ranks = (\n",
    "    pd.DataFrame\n",
    "    .from_dict(ranks, orient='index')\n",
    "    .rename_axis('id')\n",
    "    .apply(pd.Series.explode)\n",
    "    .set_index('cell_id', append=True)\n",
    ")\n",
    "\n",
    "df_ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00001756c60be8</th>\n",
       "      <td>945aea18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00015c83e2717b</th>\n",
       "      <td>aa2da37e</td>\n",
       "      <td>317b65d12af9df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001bdd4021779</th>\n",
       "      <td>a7711fde</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001daf4c2c76d</th>\n",
       "      <td>090152ca</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002115f48f982</th>\n",
       "      <td>272b483a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffc30d5a0bc46</th>\n",
       "      <td>6aed207b</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffc3b44869198</th>\n",
       "      <td>a6aaa8d7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffc63ff750064</th>\n",
       "      <td>0a1b5b65</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffcd063cda949</th>\n",
       "      <td>d971e960</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffe1d764579d5</th>\n",
       "      <td>3c40bfa6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139256 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ancestor_id       parent_id\n",
       "id                                        \n",
       "00001756c60be8    945aea18             NaN\n",
       "00015c83e2717b    aa2da37e  317b65d12af9df\n",
       "0001bdd4021779    a7711fde             NaN\n",
       "0001daf4c2c76d    090152ca             NaN\n",
       "0002115f48f982    272b483a             NaN\n",
       "...                    ...             ...\n",
       "fffc30d5a0bc46    6aed207b             NaN\n",
       "fffc3b44869198    a6aaa8d7             NaN\n",
       "fffc63ff750064    0a1b5b65             NaN\n",
       "fffcd063cda949    d971e960             NaN\n",
       "fffe1d764579d5    3c40bfa6             NaN\n",
       "\n",
       "[139256 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ancestors = pd.read_csv(data_dir / 'train_ancestors.csv', index_col='id')\n",
    "df_ancestors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "NVALID = 0.1\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=NVALID, random_state=0)\n",
    "\n",
    "ids = df.index.unique('id')\n",
    "ancestors = df_ancestors.loc[ids, 'ancestor_id']\n",
    "ids_train, ids_valid = next(splitter.split(ids, groups=ancestors))\n",
    "ids_train, ids_valid = ids[ids_train], ids[ids_valid]\n",
    "\n",
    "df_train = df.loc[ids_train, :]\n",
    "df_valid = df.loc[ids_valid, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=0.01)\n",
    "X_train = tfidf.fit_transform(df_train['source'].astype(str))\n",
    "y_train = df_ranks.loc[ids_train].to_numpy()\n",
    "groups = df_ranks.loc[ids_train].groupby('id').size().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404851, 291)\n"
     ]
    }
   ],
   "source": [
    "X_train = sparse.hstack((\n",
    "    X_train,\n",
    "    np.where(\n",
    "        df_train['cell_type'] == 'code',\n",
    "        df_train.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n",
    "        0,\n",
    "    ).reshape(-1, 1)\n",
    "))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRanker(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None, colsample_bylevel=1,\n",
       "          colsample_bynode=1, colsample_bytree=1, early_stopping_rounds=None,\n",
       "          enable_categorical=False, eval_metric=None, gamma=0, gpu_id=-1,\n",
       "          grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "          interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012, max_bin=256,\n",
       "          max_cat_to_onehot=4, max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "          min_child_weight=10, missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "          n_estimators=100, n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "          random_state=0, reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRanker</label><div class=\"sk-toggleable__content\"><pre>XGBRanker(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None, colsample_bylevel=1,\n",
       "          colsample_bynode=1, colsample_bytree=1, early_stopping_rounds=None,\n",
       "          enable_categorical=False, eval_metric=None, gamma=0, gpu_id=-1,\n",
       "          grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "          interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012, max_bin=256,\n",
       "          max_cat_to_onehot=4, max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "          min_child_weight=10, missing=nan, monotone_constraints=&#x27;()&#x27;,\n",
       "          n_estimators=100, n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "          random_state=0, reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRanker(base_score=0.5, booster='gbtree', callbacks=None, colsample_bylevel=1,\n",
       "          colsample_bynode=1, colsample_bytree=1, early_stopping_rounds=None,\n",
       "          enable_categorical=False, eval_metric=None, gamma=0, gpu_id=-1,\n",
       "          grow_policy='depthwise', importance_type=None,\n",
       "          interaction_constraints='', learning_rate=0.300000012, max_bin=256,\n",
       "          max_cat_to_onehot=4, max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "          min_child_weight=10, missing=nan, monotone_constraints='()',\n",
       "          n_estimators=100, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "          random_state=0, reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRanker\n",
    "\n",
    "model = XGBRanker(\n",
    "    min_child_weight=10,\n",
    "    subsample=0.5,\n",
    "    tree_method='hist',\n",
    ")\n",
    "model.fit(X_train, y_train, group=groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Validation Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = tfidf.transform(df_valid['source'].astype(str))\n",
    "y_valid = df_orders.loc[ids_valid]\n",
    "\n",
    "X_valid = sparse.hstack((\n",
    "    X_valid,\n",
    "    np.where(\n",
    "        df_valid['cell_type'] == \"code\",\n",
    "        df_valid.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n",
    "        0,\n",
    "    ).reshape(-1, 1)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "003926b12d6663    [a3c26e4b, d1e25146, 6c0aae3b, f09cddba, 27ed80be, 2cb34a99, c2b58f51, 394ba540, 73d2d86e, a25f090c, 7bac4bbd, 26d03...\n",
       "0045f3301bb72e    [707b1c7f, 24f94f11, 6c197fa6, 80d7eb2a, 4313301c, 0c248991, dd99a582, 3df75aa4, 4240869b, f7164a1f, f8d9b2cf, 93bc6...\n",
       "0055ad513fed6f    [229edbd1, 3063147e, 6065659c, d60d3a5a, d49fc3d9, 9f53b404, 9a3846c5, 5fcd0218, 5f6df0b6, 38a769c5, ca851498, 35ec0...\n",
       "00fc8fe3f3daee    [c6778546, 62e8d610, 1fde2bfb, eb2c7a88, 1c0ee524, ca3a8c7b, 012db1fd, 655aa141, 801e80cf, 0b20993b, 667c2ffd, ee68e...\n",
       "0147ab49cc2a8f    [3b577bcd, de194e03, a7547a1d, c8cb36b1, a490b4a5, 323269ca, 2eec255b, 9092f5a3, e033fd08, deedd97c, dc49a6b3, 3fe1d...\n",
       "014ff654f9260c    [84ae0de6, 6e3b274f, 5d637275, 343d4b0a, 49fa1013, ea061a6d, 9898e036, d2829aec, c6689c36, 22af7e39, 95f736ba, 3451c...\n",
       "017ffea4363ced    [43ead210, 3c78d54c, 12fc37f8, 24cab715, 00cb87a3, c1b28550, 8ad0c111, 4d0f65a6, 41c6d154, e2cf3918, 7d63cef5, ebd5b...\n",
       "0192e704f7465e    [cf9fe075, 2923d378, 66231d48, aac102a1, 75e31376, 89fd9b61, 9c7666d6, d3b0aba9, 8ce94419, 6988b60f, 03b17408, 85c96...\n",
       "01be6437772541    [91e413d5, ce525c9c, a955f27d, f192fd9e, 0f667449, aeed4596, 1c1f9689, c694a158, 0bf73791, 8ba81ec7, 31ed183a, 0628e...\n",
       "01faf613cb7982    [c8edc8bb, 35b06cd8, bb44ad72, 9acf4c66, f0123bdd, d8ab385e, f5042802, 465af5e0, ae78c426, 714dfa0f, 432fa0e0, 68754...\n",
       "Name: cell_id, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pd.DataFrame({'rank': model.predict(X_valid)}, index=df_valid.index)\n",
    "y_pred = (\n",
    "    y_pred\n",
    "    .sort_values(['id', 'rank'])\n",
    "    .reset_index('cell_id')\n",
    "    .groupby('id')['cell_id'].apply(list)\n",
    ")\n",
    "y_pred.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91e413d5</th>\n",
       "      <td>code</td>\n",
       "      <td># load modules\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\nimport...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ce525c9c</th>\n",
       "      <td>code</td>\n",
       "      <td># display column limita\\npd.set_option('display.max_columns',500)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a955f27d</th>\n",
       "      <td>code</td>\n",
       "      <td># load data\\ntrain = pd.read_csv('../input/xente-challenge/training.csv')\\nvalidation = pd.read_csv('../input/xente-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f192fd9e</th>\n",
       "      <td>code</td>\n",
       "      <td># checking the balance of the data\\nprint('The number of Non-Frauds are: ' + str(train['FraudResult'].value_counts()...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0f667449</th>\n",
       "      <td>code</td>\n",
       "      <td># visualize category class\\nsns.countplot(x='FraudResult', data=train)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1c1f9689</th>\n",
       "      <td>code</td>\n",
       "      <td># SMOTE\\n# oversampling\\nfrom imblearn.over_sampling import SMOTE\\n\\ncount_class_0, count_class_1 = train.FraudResul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c694a158</th>\n",
       "      <td>code</td>\n",
       "      <td>train_class_1_over = train_class_1.sample(count_class_0, replace=True)\\ntrain_test_over = pd.concat([train_class_0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0bf73791</th>\n",
       "      <td>code</td>\n",
       "      <td>train1 = train_test_over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8ba81ec7</th>\n",
       "      <td>code</td>\n",
       "      <td>numeric_features = train.select_dtypes(include=[np.number])\\nnumeric_features.columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0628e51f</th>\n",
       "      <td>code</td>\n",
       "      <td>categorical_features = train.select_dtypes(include=[np.object])\\ncategorical_features.columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31ed183a</th>\n",
       "      <td>code</td>\n",
       "      <td># pricing and fraudresults\\nsns.countplot(y='ProviderId', data=train1, hue='FraudResult')\\nplt.show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8f36e182</th>\n",
       "      <td>code</td>\n",
       "      <td># pricingstrategy and fraudresult\\nsns.countplot(x='PricingStrategy', data=train1, hue='FraudResult')\\nplt.show()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0fb8c17c</th>\n",
       "      <td>code</td>\n",
       "      <td># product category and fraudresult\\nsns.countplot(y='ProductCategory',data = train1, hue = 'FraudResult')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc9d6a8d</th>\n",
       "      <td>code</td>\n",
       "      <td># ProductId and fraudresult\\nsns.countplot(y='ProductId', data = train1, hue = 'FraudResult')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67126527</th>\n",
       "      <td>code</td>\n",
       "      <td># channelid and fraudresult\\nsns.countplot(x='ChannelId', data = train1, hue = 'FraudResult')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d468f702</th>\n",
       "      <td>code</td>\n",
       "      <td># TIME WRANGLING\\n# train1\\ntrain1['hour'] = pd.to_datetime(train1.TransactionStartTime).dt.hour\\ntrain1['minute'] =...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0700d90c</th>\n",
       "      <td>code</td>\n",
       "      <td>train1['period'] = np.nan\\nvalidation['period'] = np.nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95a4d97b</th>\n",
       "      <td>code</td>\n",
       "      <td># train1\\ntrain1.loc[train1.hour &lt; 7, 'period']= 'em'\\ntrain1.loc[(train1.hour &gt;= 7) &amp; (train1.hour &lt; 11), 'period']...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f20b5b40</th>\n",
       "      <td>code</td>\n",
       "      <td>train1['minutes'] = train1['hour']*60 + train1['minute'] + train1['day']*24*60\\nvalidation['minutes'] = validation['...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d7b86700</th>\n",
       "      <td>code</td>\n",
       "      <td># drop features\\ntrain1 = train1.drop(['BatchId','AccountId','SubscriptionId','CustomerId','CurrencyCode','CountryCo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c3f9f09a</th>\n",
       "      <td>code</td>\n",
       "      <td># normalize\\nfrom sklearn.preprocessing import MinMaxScaler\\n# minutes\\nscaler_minutes = MinMaxScaler()\\ntrain1['min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d408a511</th>\n",
       "      <td>code</td>\n",
       "      <td>validation1 = validation.copy()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605ab69d</th>\n",
       "      <td>code</td>\n",
       "      <td># drop Transactionid\\ntrain1 = train1.drop(['TransactionId'], axis=1)\\nvalidation = validation.drop(['TransactionId'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e72eee6b</th>\n",
       "      <td>code</td>\n",
       "      <td># dummies\\ntrain1 = pd.get_dummies(train1, prefix_sep='_', drop_first=True)\\nvalidation = pd.get_dummies(validation,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab562a72</th>\n",
       "      <td>code</td>\n",
       "      <td># drop irrelevant features\\ntrain1 = train1.drop(['ProviderId_ProviderId_2','ProductId_ProductId_10','ProductId_Prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85aaea6f</th>\n",
       "      <td>code</td>\n",
       "      <td># bring the fraudresult column to be 1st\\nFraudResult = train1['FraudResult']\\ntrain1.drop(['FraudResult'], axis=1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d311835b</th>\n",
       "      <td>code</td>\n",
       "      <td># rename columns\\ntrain1.rename(columns={'ProviderId_ProviderId_3':'ProviderId3',\\n                       'ProviderI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6f7b0940</th>\n",
       "      <td>code</td>\n",
       "      <td>train1.head()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72a89880</th>\n",
       "      <td>code</td>\n",
       "      <td>train1['exponential'] = np.log(train1['Value']**2 + train1['PricingStrategy']**2 + train1['ProviderId3']**2 + train1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff29d27d</th>\n",
       "      <td>code</td>\n",
       "      <td>train1.head()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4a563476</th>\n",
       "      <td>code</td>\n",
       "      <td>scaler_exponential = MinMaxScaler()\\ntrain1['exponential'] = train1['exponential'].astype('float64')\\ntrain1['expone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8556c55c</th>\n",
       "      <td>code</td>\n",
       "      <td># selection of features\\ny = train1.FraudResult\\nX = train1.drop(['FraudResult'], axis=1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e2001a7c</th>\n",
       "      <td>code</td>\n",
       "      <td># split data\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>defa0fa1</th>\n",
       "      <td>code</td>\n",
       "      <td># random forest\\nfrom sklearn.ensemble import RandomForestClassifier\\nRFC = RandomForestClassifier()\\nRFC = RFC.fit(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2b8883d5</th>\n",
       "      <td>code</td>\n",
       "      <td># bring the test dataset\\n# random forest\\nfrom sklearn.ensemble import RandomForestClassifier\\nRFC = RandomForestCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bde41fef</th>\n",
       "      <td>code</td>\n",
       "      <td>submission = pd.DataFrame({'TransactionId':validation1['TransactionId'],'FraudResult':submit})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3faeb622</th>\n",
       "      <td>code</td>\n",
       "      <td>submission.to_csv('submit70.csv', index=False)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910224b7</th>\n",
       "      <td>code</td>\n",
       "      <td># save the model to disk\\nfilename = 'XenteFraud_detection_model_7.sav'\\npickle.dump(RFC, open(filename, 'wb'))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9383b421</th>\n",
       "      <td>markdown</td>\n",
       "      <td>FEATURE ENGINEERING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ef7fd942</th>\n",
       "      <td>markdown</td>\n",
       "      <td>HIGEST SCORE ON THE COMPETITION IS 74.5%. HOPE TO INCREASE IN THE NEAR FUTURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8c2365ed</th>\n",
       "      <td>markdown</td>\n",
       "      <td>1. find the outliers outliers and remove them\\n2. wrangle the time feature and include it to the rest of the data\\n3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e3c42213</th>\n",
       "      <td>markdown</td>\n",
       "      <td>the data is highly imbalanced, non frauds = 99.8% and frauds = 0.2%. It calls for smote balancing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feb0e45e</th>\n",
       "      <td>markdown</td>\n",
       "      <td>BIVARIATE VISUALIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aeed4596</th>\n",
       "      <td>markdown</td>\n",
       "      <td>EXPLORATORY DATA ANALYSIS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_type                                                                                                                   source\n",
       "cell_id                                                                                                                                    \n",
       "91e413d5      code  # load modules\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\nimport...\n",
       "ce525c9c      code                                                        # display column limita\\npd.set_option('display.max_columns',500)\n",
       "a955f27d      code  # load data\\ntrain = pd.read_csv('../input/xente-challenge/training.csv')\\nvalidation = pd.read_csv('../input/xente-...\n",
       "f192fd9e      code  # checking the balance of the data\\nprint('The number of Non-Frauds are: ' + str(train['FraudResult'].value_counts()...\n",
       "0f667449      code                                                   # visualize category class\\nsns.countplot(x='FraudResult', data=train)\n",
       "1c1f9689      code  # SMOTE\\n# oversampling\\nfrom imblearn.over_sampling import SMOTE\\n\\ncount_class_0, count_class_1 = train.FraudResul...\n",
       "c694a158      code  train_class_1_over = train_class_1.sample(count_class_0, replace=True)\\ntrain_test_over = pd.concat([train_class_0, ...\n",
       "0bf73791      code                                                                                                train1 = train_test_over \n",
       "8ba81ec7      code                                    numeric_features = train.select_dtypes(include=[np.number])\\nnumeric_features.columns\n",
       "0628e51f      code                            categorical_features = train.select_dtypes(include=[np.object])\\ncategorical_features.columns\n",
       "31ed183a      code                      # pricing and fraudresults\\nsns.countplot(y='ProviderId', data=train1, hue='FraudResult')\\nplt.show\n",
       "8f36e182      code        # pricingstrategy and fraudresult\\nsns.countplot(x='PricingStrategy', data=train1, hue='FraudResult')\\nplt.show()\n",
       "0fb8c17c      code                # product category and fraudresult\\nsns.countplot(y='ProductCategory',data = train1, hue = 'FraudResult')\n",
       "cc9d6a8d      code                            # ProductId and fraudresult\\nsns.countplot(y='ProductId', data = train1, hue = 'FraudResult')\n",
       "67126527      code                            # channelid and fraudresult\\nsns.countplot(x='ChannelId', data = train1, hue = 'FraudResult')\n",
       "d468f702      code  # TIME WRANGLING\\n# train1\\ntrain1['hour'] = pd.to_datetime(train1.TransactionStartTime).dt.hour\\ntrain1['minute'] =...\n",
       "0700d90c      code                                                                 train1['period'] = np.nan\\nvalidation['period'] = np.nan\n",
       "95a4d97b      code  # train1\\ntrain1.loc[train1.hour < 7, 'period']= 'em'\\ntrain1.loc[(train1.hour >= 7) & (train1.hour < 11), 'period']...\n",
       "f20b5b40      code  train1['minutes'] = train1['hour']*60 + train1['minute'] + train1['day']*24*60\\nvalidation['minutes'] = validation['...\n",
       "d7b86700      code  # drop features\\ntrain1 = train1.drop(['BatchId','AccountId','SubscriptionId','CustomerId','CurrencyCode','CountryCo...\n",
       "c3f9f09a      code  # normalize\\nfrom sklearn.preprocessing import MinMaxScaler\\n# minutes\\nscaler_minutes = MinMaxScaler()\\ntrain1['min...\n",
       "d408a511      code                                                                                          validation1 = validation.copy()\n",
       "605ab69d      code  # drop Transactionid\\ntrain1 = train1.drop(['TransactionId'], axis=1)\\nvalidation = validation.drop(['TransactionId'...\n",
       "e72eee6b      code  # dummies\\ntrain1 = pd.get_dummies(train1, prefix_sep='_', drop_first=True)\\nvalidation = pd.get_dummies(validation,...\n",
       "ab562a72      code  # drop irrelevant features\\ntrain1 = train1.drop(['ProviderId_ProviderId_2','ProductId_ProductId_10','ProductId_Prod...\n",
       "85aaea6f      code  # bring the fraudresult column to be 1st\\nFraudResult = train1['FraudResult']\\ntrain1.drop(['FraudResult'], axis=1, ...\n",
       "d311835b      code  # rename columns\\ntrain1.rename(columns={'ProviderId_ProviderId_3':'ProviderId3',\\n                       'ProviderI...\n",
       "6f7b0940      code                                                                                                            train1.head()\n",
       "72a89880      code  train1['exponential'] = np.log(train1['Value']**2 + train1['PricingStrategy']**2 + train1['ProviderId3']**2 + train1...\n",
       "ff29d27d      code                                                                                                            train1.head()\n",
       "4a563476      code  scaler_exponential = MinMaxScaler()\\ntrain1['exponential'] = train1['exponential'].astype('float64')\\ntrain1['expone...\n",
       "8556c55c      code                                # selection of features\\ny = train1.FraudResult\\nX = train1.drop(['FraudResult'], axis=1)\n",
       "e2001a7c      code  # split data\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_sp...\n",
       "defa0fa1      code  # random forest\\nfrom sklearn.ensemble import RandomForestClassifier\\nRFC = RandomForestClassifier()\\nRFC = RFC.fit(...\n",
       "2b8883d5      code  # bring the test dataset\\n# random forest\\nfrom sklearn.ensemble import RandomForestClassifier\\nRFC = RandomForestCl...\n",
       "bde41fef      code                           submission = pd.DataFrame({'TransactionId':validation1['TransactionId'],'FraudResult':submit})\n",
       "3faeb622      code                                                                           submission.to_csv('submit70.csv', index=False)\n",
       "910224b7      code          # save the model to disk\\nfilename = 'XenteFraud_detection_model_7.sav'\\npickle.dump(RFC, open(filename, 'wb'))\n",
       "9383b421  markdown                                                                                                      FEATURE ENGINEERING\n",
       "ef7fd942  markdown                                            HIGEST SCORE ON THE COMPETITION IS 74.5%. HOPE TO INCREASE IN THE NEAR FUTURE\n",
       "8c2365ed  markdown  1. find the outliers outliers and remove them\\n2. wrangle the time feature and include it to the rest of the data\\n3...\n",
       "e3c42213  markdown                       the data is highly imbalanced, non frauds = 99.8% and frauds = 0.2%. It calls for smote balancing.\n",
       "feb0e45e  markdown                                                                                                  BIVARIATE VISUALIZATION\n",
       "aeed4596  markdown                                                                                                EXPLORATORY DATA ANALYSIS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91e413d5</th>\n",
       "      <td>code</td>\n",
       "      <td># load modules\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\nimport...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ce525c9c</th>\n",
       "      <td>code</td>\n",
       "      <td># display column limita\\npd.set_option('display.max_columns',500)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a955f27d</th>\n",
       "      <td>code</td>\n",
       "      <td># load data\\ntrain = pd.read_csv('../input/xente-challenge/training.csv')\\nvalidation = pd.read_csv('../input/xente-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f192fd9e</th>\n",
       "      <td>code</td>\n",
       "      <td># checking the balance of the data\\nprint('The number of Non-Frauds are: ' + str(train['FraudResult'].value_counts()...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0f667449</th>\n",
       "      <td>code</td>\n",
       "      <td># visualize category class\\nsns.countplot(x='FraudResult', data=train)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aeed4596</th>\n",
       "      <td>markdown</td>\n",
       "      <td>EXPLORATORY DATA ANALYSIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1c1f9689</th>\n",
       "      <td>code</td>\n",
       "      <td># SMOTE\\n# oversampling\\nfrom imblearn.over_sampling import SMOTE\\n\\ncount_class_0, count_class_1 = train.FraudResul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c694a158</th>\n",
       "      <td>code</td>\n",
       "      <td>train_class_1_over = train_class_1.sample(count_class_0, replace=True)\\ntrain_test_over = pd.concat([train_class_0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0bf73791</th>\n",
       "      <td>code</td>\n",
       "      <td>train1 = train_test_over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8ba81ec7</th>\n",
       "      <td>code</td>\n",
       "      <td>numeric_features = train.select_dtypes(include=[np.number])\\nnumeric_features.columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31ed183a</th>\n",
       "      <td>code</td>\n",
       "      <td># pricing and fraudresults\\nsns.countplot(y='ProviderId', data=train1, hue='FraudResult')\\nplt.show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0628e51f</th>\n",
       "      <td>code</td>\n",
       "      <td>categorical_features = train.select_dtypes(include=[np.object])\\ncategorical_features.columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8f36e182</th>\n",
       "      <td>code</td>\n",
       "      <td># pricingstrategy and fraudresult\\nsns.countplot(x='PricingStrategy', data=train1, hue='FraudResult')\\nplt.show()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e3c42213</th>\n",
       "      <td>markdown</td>\n",
       "      <td>the data is highly imbalanced, non frauds = 99.8% and frauds = 0.2%. It calls for smote balancing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0fb8c17c</th>\n",
       "      <td>code</td>\n",
       "      <td># product category and fraudresult\\nsns.countplot(y='ProductCategory',data = train1, hue = 'FraudResult')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc9d6a8d</th>\n",
       "      <td>code</td>\n",
       "      <td># ProductId and fraudresult\\nsns.countplot(y='ProductId', data = train1, hue = 'FraudResult')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8c2365ed</th>\n",
       "      <td>markdown</td>\n",
       "      <td>1. find the outliers outliers and remove them\\n2. wrangle the time feature and include it to the rest of the data\\n3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67126527</th>\n",
       "      <td>code</td>\n",
       "      <td># channelid and fraudresult\\nsns.countplot(x='ChannelId', data = train1, hue = 'FraudResult')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9383b421</th>\n",
       "      <td>markdown</td>\n",
       "      <td>FEATURE ENGINEERING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feb0e45e</th>\n",
       "      <td>markdown</td>\n",
       "      <td>BIVARIATE VISUALIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85aaea6f</th>\n",
       "      <td>code</td>\n",
       "      <td># bring the fraudresult column to be 1st\\nFraudResult = train1['FraudResult']\\ntrain1.drop(['FraudResult'], axis=1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ef7fd942</th>\n",
       "      <td>markdown</td>\n",
       "      <td>HIGEST SCORE ON THE COMPETITION IS 74.5%. HOPE TO INCREASE IN THE NEAR FUTURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d468f702</th>\n",
       "      <td>code</td>\n",
       "      <td># TIME WRANGLING\\n# train1\\ntrain1['hour'] = pd.to_datetime(train1.TransactionStartTime).dt.hour\\ntrain1['minute'] =...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d7b86700</th>\n",
       "      <td>code</td>\n",
       "      <td># drop features\\ntrain1 = train1.drop(['BatchId','AccountId','SubscriptionId','CustomerId','CurrencyCode','CountryCo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0700d90c</th>\n",
       "      <td>code</td>\n",
       "      <td>train1['period'] = np.nan\\nvalidation['period'] = np.nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95a4d97b</th>\n",
       "      <td>code</td>\n",
       "      <td># train1\\ntrain1.loc[train1.hour &lt; 7, 'period']= 'em'\\ntrain1.loc[(train1.hour &gt;= 7) &amp; (train1.hour &lt; 11), 'period']...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6f7b0940</th>\n",
       "      <td>code</td>\n",
       "      <td>train1.head()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d311835b</th>\n",
       "      <td>code</td>\n",
       "      <td># rename columns\\ntrain1.rename(columns={'ProviderId_ProviderId_3':'ProviderId3',\\n                       'ProviderI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f20b5b40</th>\n",
       "      <td>code</td>\n",
       "      <td>train1['minutes'] = train1['hour']*60 + train1['minute'] + train1['day']*24*60\\nvalidation['minutes'] = validation['...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605ab69d</th>\n",
       "      <td>code</td>\n",
       "      <td># drop Transactionid\\ntrain1 = train1.drop(['TransactionId'], axis=1)\\nvalidation = validation.drop(['TransactionId'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d408a511</th>\n",
       "      <td>code</td>\n",
       "      <td>validation1 = validation.copy()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4a563476</th>\n",
       "      <td>code</td>\n",
       "      <td>scaler_exponential = MinMaxScaler()\\ntrain1['exponential'] = train1['exponential'].astype('float64')\\ntrain1['expone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff29d27d</th>\n",
       "      <td>code</td>\n",
       "      <td>train1.head()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c3f9f09a</th>\n",
       "      <td>code</td>\n",
       "      <td># normalize\\nfrom sklearn.preprocessing import MinMaxScaler\\n# minutes\\nscaler_minutes = MinMaxScaler()\\ntrain1['min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8556c55c</th>\n",
       "      <td>code</td>\n",
       "      <td># selection of features\\ny = train1.FraudResult\\nX = train1.drop(['FraudResult'], axis=1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab562a72</th>\n",
       "      <td>code</td>\n",
       "      <td># drop irrelevant features\\ntrain1 = train1.drop(['ProviderId_ProviderId_2','ProductId_ProductId_10','ProductId_Prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e72eee6b</th>\n",
       "      <td>code</td>\n",
       "      <td># dummies\\ntrain1 = pd.get_dummies(train1, prefix_sep='_', drop_first=True)\\nvalidation = pd.get_dummies(validation,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e2001a7c</th>\n",
       "      <td>code</td>\n",
       "      <td># split data\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72a89880</th>\n",
       "      <td>code</td>\n",
       "      <td>train1['exponential'] = np.log(train1['Value']**2 + train1['PricingStrategy']**2 + train1['ProviderId3']**2 + train1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>defa0fa1</th>\n",
       "      <td>code</td>\n",
       "      <td># random forest\\nfrom sklearn.ensemble import RandomForestClassifier\\nRFC = RandomForestClassifier()\\nRFC = RFC.fit(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910224b7</th>\n",
       "      <td>code</td>\n",
       "      <td># save the model to disk\\nfilename = 'XenteFraud_detection_model_7.sav'\\npickle.dump(RFC, open(filename, 'wb'))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2b8883d5</th>\n",
       "      <td>code</td>\n",
       "      <td># bring the test dataset\\n# random forest\\nfrom sklearn.ensemble import RandomForestClassifier\\nRFC = RandomForestCl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bde41fef</th>\n",
       "      <td>code</td>\n",
       "      <td>submission = pd.DataFrame({'TransactionId':validation1['TransactionId'],'FraudResult':submit})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3faeb622</th>\n",
       "      <td>code</td>\n",
       "      <td>submission.to_csv('submit70.csv', index=False)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cell_type                                                                                                                   source\n",
       "cell_id                                                                                                                                    \n",
       "91e413d5      code  # load modules\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\nimport...\n",
       "ce525c9c      code                                                        # display column limita\\npd.set_option('display.max_columns',500)\n",
       "a955f27d      code  # load data\\ntrain = pd.read_csv('../input/xente-challenge/training.csv')\\nvalidation = pd.read_csv('../input/xente-...\n",
       "f192fd9e      code  # checking the balance of the data\\nprint('The number of Non-Frauds are: ' + str(train['FraudResult'].value_counts()...\n",
       "0f667449      code                                                   # visualize category class\\nsns.countplot(x='FraudResult', data=train)\n",
       "aeed4596  markdown                                                                                                EXPLORATORY DATA ANALYSIS\n",
       "1c1f9689      code  # SMOTE\\n# oversampling\\nfrom imblearn.over_sampling import SMOTE\\n\\ncount_class_0, count_class_1 = train.FraudResul...\n",
       "c694a158      code  train_class_1_over = train_class_1.sample(count_class_0, replace=True)\\ntrain_test_over = pd.concat([train_class_0, ...\n",
       "0bf73791      code                                                                                                train1 = train_test_over \n",
       "8ba81ec7      code                                    numeric_features = train.select_dtypes(include=[np.number])\\nnumeric_features.columns\n",
       "31ed183a      code                      # pricing and fraudresults\\nsns.countplot(y='ProviderId', data=train1, hue='FraudResult')\\nplt.show\n",
       "0628e51f      code                            categorical_features = train.select_dtypes(include=[np.object])\\ncategorical_features.columns\n",
       "8f36e182      code        # pricingstrategy and fraudresult\\nsns.countplot(x='PricingStrategy', data=train1, hue='FraudResult')\\nplt.show()\n",
       "e3c42213  markdown                       the data is highly imbalanced, non frauds = 99.8% and frauds = 0.2%. It calls for smote balancing.\n",
       "0fb8c17c      code                # product category and fraudresult\\nsns.countplot(y='ProductCategory',data = train1, hue = 'FraudResult')\n",
       "cc9d6a8d      code                            # ProductId and fraudresult\\nsns.countplot(y='ProductId', data = train1, hue = 'FraudResult')\n",
       "8c2365ed  markdown  1. find the outliers outliers and remove them\\n2. wrangle the time feature and include it to the rest of the data\\n3...\n",
       "67126527      code                            # channelid and fraudresult\\nsns.countplot(x='ChannelId', data = train1, hue = 'FraudResult')\n",
       "9383b421  markdown                                                                                                      FEATURE ENGINEERING\n",
       "feb0e45e  markdown                                                                                                  BIVARIATE VISUALIZATION\n",
       "85aaea6f      code  # bring the fraudresult column to be 1st\\nFraudResult = train1['FraudResult']\\ntrain1.drop(['FraudResult'], axis=1, ...\n",
       "ef7fd942  markdown                                            HIGEST SCORE ON THE COMPETITION IS 74.5%. HOPE TO INCREASE IN THE NEAR FUTURE\n",
       "d468f702      code  # TIME WRANGLING\\n# train1\\ntrain1['hour'] = pd.to_datetime(train1.TransactionStartTime).dt.hour\\ntrain1['minute'] =...\n",
       "d7b86700      code  # drop features\\ntrain1 = train1.drop(['BatchId','AccountId','SubscriptionId','CustomerId','CurrencyCode','CountryCo...\n",
       "0700d90c      code                                                                 train1['period'] = np.nan\\nvalidation['period'] = np.nan\n",
       "95a4d97b      code  # train1\\ntrain1.loc[train1.hour < 7, 'period']= 'em'\\ntrain1.loc[(train1.hour >= 7) & (train1.hour < 11), 'period']...\n",
       "6f7b0940      code                                                                                                            train1.head()\n",
       "d311835b      code  # rename columns\\ntrain1.rename(columns={'ProviderId_ProviderId_3':'ProviderId3',\\n                       'ProviderI...\n",
       "f20b5b40      code  train1['minutes'] = train1['hour']*60 + train1['minute'] + train1['day']*24*60\\nvalidation['minutes'] = validation['...\n",
       "605ab69d      code  # drop Transactionid\\ntrain1 = train1.drop(['TransactionId'], axis=1)\\nvalidation = validation.drop(['TransactionId'...\n",
       "d408a511      code                                                                                          validation1 = validation.copy()\n",
       "4a563476      code  scaler_exponential = MinMaxScaler()\\ntrain1['exponential'] = train1['exponential'].astype('float64')\\ntrain1['expone...\n",
       "ff29d27d      code                                                                                                            train1.head()\n",
       "c3f9f09a      code  # normalize\\nfrom sklearn.preprocessing import MinMaxScaler\\n# minutes\\nscaler_minutes = MinMaxScaler()\\ntrain1['min...\n",
       "8556c55c      code                                # selection of features\\ny = train1.FraudResult\\nX = train1.drop(['FraudResult'], axis=1)\n",
       "ab562a72      code  # drop irrelevant features\\ntrain1 = train1.drop(['ProviderId_ProviderId_2','ProductId_ProductId_10','ProductId_Prod...\n",
       "e72eee6b      code  # dummies\\ntrain1 = pd.get_dummies(train1, prefix_sep='_', drop_first=True)\\nvalidation = pd.get_dummies(validation,...\n",
       "e2001a7c      code  # split data\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_sp...\n",
       "72a89880      code  train1['exponential'] = np.log(train1['Value']**2 + train1['PricingStrategy']**2 + train1['ProviderId3']**2 + train1...\n",
       "defa0fa1      code  # random forest\\nfrom sklearn.ensemble import RandomForestClassifier\\nRFC = RandomForestClassifier()\\nRFC = RFC.fit(...\n",
       "910224b7      code          # save the model to disk\\nfilename = 'XenteFraud_detection_model_7.sav'\\npickle.dump(RFC, open(filename, 'wb'))\n",
       "2b8883d5      code  # bring the test dataset\\n# random forest\\nfrom sklearn.ensemble import RandomForestClassifier\\nRFC = RandomForestCl...\n",
       "bde41fef      code                           submission = pd.DataFrame({'TransactionId':validation1['TransactionId'],'FraudResult':submit})\n",
       "3faeb622      code                                                                           submission.to_csv('submit70.csv', index=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_id = df_valid.index.get_level_values('id').unique()[8]\n",
    "display(df.loc[nb_id])\n",
    "display(df.loc[nb_id].loc[y_pred.loc[nb_id]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect\n",
    "\n",
    "def count_inversions(a):\n",
    "    inversions = 0\n",
    "    sorted_so_far = []\n",
    "    for i, u in enumerate(a):\n",
    "        j = bisect(sorted_so_far, u)\n",
    "        inversions += i - j\n",
    "        sorted_so_far.insert(j, u)\n",
    "    return inversions\n",
    "\n",
    "\n",
    "def kendall_tau(ground_truth, predictions):\n",
    "    total_inversions = 0\n",
    "    total_2max = 0\n",
    "    for gt, pred in zip(ground_truth, predictions):\n",
    "        ranks = [gt.index(x) for x in pred]\n",
    "        total_inversions += count_inversions(ranks)\n",
    "        n = len(gt)\n",
    "        total_2max += n * (n - 1)\n",
    "    return 1 - 4 * total_inversions / total_2max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.415278693883941"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dummy = df_valid.reset_index('cell_id').groupby('id')['cell_id'].apply(list)\n",
    "kendall_tau(y_valid, y_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6015841825781357"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendall_tau(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test NBs: 100%|██████████| 4/4 [00:00<00:00, 219.71it/s]\n"
     ]
    }
   ],
   "source": [
    "paths_test = list((data_dir / 'test').glob('*.json'))\n",
    "notebooks_test = [\n",
    "    read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n",
    "]\n",
    "df_test = (\n",
    "    pd.concat(notebooks_test)\n",
    "    .set_index('id', append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level='id', sort_remaining=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tfidf.transform(df_test['source'].astype(str))\n",
    "X_test = sparse.hstack((\n",
    "    X_test,\n",
    "    np.where(\n",
    "        df_test['cell_type'] == 'code',\n",
    "        df_test.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n",
    "        0,\n",
    "    ).reshape(-1, 1)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0009d135ece78d    [ddfd239c, c6cd22db, 1372ae9b, 7f388a41, 90ed07ab, 8cb8d28a, 2843a25a, f9893819, 06dbf8cf, 0a226b6a, ba55e576, 39e93...\n",
       "0010483c12ba9b                       [54c7cab3, fe66203e, 7f270e34, 5ce8863c, 7844d5f8, 4a32c095, 4a0777c4, 02a0be6d, 865ad516, 4703bb6d]\n",
       "0010a919d60e4f    [aafc3d23, b7578789, 80e077ec, b190ebb4, ed415c3c, 322850af, c069ed33, 868c4eae, 80433cf3, 5e8c5e7e, d2f722a5, 8ce62...\n",
       "0028856e09c5b7                                                                                   [012c9d02, d22526d1, 3ae7ece3, eb293dfc]\n",
       "Name: cell_id, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_infer = pd.DataFrame({'rank': model.predict(X_test)}, index=df_test.index)\n",
    "y_infer = y_infer.sort_values(['id', 'rank']).reset_index(\n",
    "    'cell_id').groupby('id')['cell_id'].apply(list)\n",
    "y_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3694/87886191.py:1: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  y_sample = pd.read_csv(data_dir / 'sample_submission.csv',\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "0009d135ece78d       ddfd239c c6cd22db 1372ae9b 90ed07ab 7f388a41 2843a25a 06dbf8cf f9893819 ba55e576 39e937ec e25aa9bd 0a226b6a 8cb8d28a\n",
       "0010483c12ba9b                                  54c7cab3 fe66203e 7844d5f8 5ce8863c 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d 7f270e34\n",
       "0010a919d60e4f    aafc3d23 80e077ec b190ebb4 ed415c3c 322850af c069ed33 868c4eae 80433cf3 bd8fbd76 0e2529e8 1345b8b2 cdae286f 4907b9ef...\n",
       "0028856e09c5b7                                                                                        012c9d02 d22526d1 3ae7ece3 eb293dfc\n",
       "Name: cell_order, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sample = pd.read_csv(data_dir / 'sample_submission.csv',\n",
    "                       index_col='id', squeeze=True)\n",
    "y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0009d135ece78d       ddfd239c c6cd22db 1372ae9b 7f388a41 90ed07ab 8cb8d28a 2843a25a f9893819 06dbf8cf 0a226b6a ba55e576 39e937ec e25aa9bd\n",
       "0010483c12ba9b                                  54c7cab3 fe66203e 7f270e34 5ce8863c 7844d5f8 4a32c095 4a0777c4 02a0be6d 865ad516 4703bb6d\n",
       "0010a919d60e4f    aafc3d23 b7578789 80e077ec b190ebb4 ed415c3c 322850af c069ed33 868c4eae 80433cf3 5e8c5e7e d2f722a5 8ce62db4 4ae17669...\n",
       "0028856e09c5b7                                                                                        012c9d02 d22526d1 3ae7ece3 eb293dfc\n",
       "Name: cell_order, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_submit = (\n",
    "    y_infer\n",
    "    .apply(' '.join)  # list of ids -> string of ids\n",
    "    .rename_axis('id')\n",
    "    .rename('cell_order')\n",
    ")\n",
    "y_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submit.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('python_ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d90a5e87c106f342b28d760c77453d54b75444cd97381247197e9f8b1d79c69f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
